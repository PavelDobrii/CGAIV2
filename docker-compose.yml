services:
  llm:
    # Use the official TGI image from GitHub Container Registry
    image: ghcr.io/huggingface/text-generation-inference:latest
    # Exposes the LLM server on http://localhost:8080
    ports:
      - "8080:80"
    volumes:
      - ./orchestrator/outputs:/outputs
    environment:
      - MODEL_ID=deepseek-ai/deepseek-r1-distill-qwen-14b
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  tts:
    image: synesthesiam/opentts:latest
    # Exposes the TTS server on http://localhost:5500
    ports:
      - "5500:5500"
    volumes:
      - ./orchestrator/outputs:/outputs
      - ./services/tts_server/voices.yml:/config/voices.yml:ro
    environment:
      - VOICE_CONFIG=/config/voices.yml

  kokoro:
    image: ghcr.io/hexgrad/kokoro:latest
    # Exposes the Kokoro server on http://localhost:5600
    ports:
      - "5600:5600"
    volumes:
      - ./orchestrator/outputs:/outputs

